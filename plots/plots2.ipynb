{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import powerlaw\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.dates import DateFormatter\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from scipy.stats import spearmanr\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENS = ['sUSD','FRAX','EURS','XCHF','XAUt','FEI','GUSD','BUSD']\n",
    "FIRST_BLOCKS = [5767935,11465581,5835474,6622987,9339031,12168368,6302486,8523552]\n",
    "LAST_BLOCK = 14497033\n",
    "colors = ['#E9B872', '#90A959','#A63D40','#6494AA','#1E5085','#433061','#565656','#151515']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimates best alpha for power-law fit\n",
    "for TOKEN in TOKENS:\n",
    "    velocity = pd.read_csv('{}_microVelocities_last.csv'.format(TOKEN))\n",
    "    velocity = velocity.set_index('timestamp')\n",
    "    velocity = velocity.drop(['total'],axis=1)\n",
    "    velocity = pd.DataFrame(velocity.T)\n",
    "    DATES_ = velocity.columns.values.tolist()\n",
    "    velocity = velocity.reset_index()\n",
    "    alpha = {}\n",
    "    xmin = {}\n",
    "    test = {}\n",
    "    for DATE in DATES_:\n",
    "        v = velocity[['index',DATE]]\n",
    "        v = v.sort_values(by=[DATE],ascending=False)\n",
    "        v = v.loc[v[DATE] > 0]\n",
    "        v[DATE] = v[DATE] / v[DATE].sum()\n",
    "        d1 = v[DATE].to_numpy()\n",
    "        fit = powerlaw.Fit(d1)\n",
    "        alpha[DATE] = fit.power_law.alpha\n",
    "        xmin[DATE] = fit.power_law.xmin\n",
    "\n",
    "       \n",
    "    df = pd.DataFrame.from_dict(alpha, orient='index',columns=['alpha']).reset_index()\n",
    "    df = df.rename(columns={'index':'timestamp'})\n",
    "    df.to_csv('{}_alpha.csv'.format(TOKEN), index=False)\n",
    "    df = pd.DataFrame.from_dict(xmin, orient='index',columns=['alpha']).reset_index()\n",
    "    df = df.rename(columns={'index':'timestamp'})\n",
    "    df.to_csv('{}_xmin.csv'.format(TOKEN), index=False)\n",
    "    f = open(\"{}_distribution_test.pkl\".format(TOKEN),\"wb\")\n",
    "    pickle.dump(test,f)\n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log-likelihood ratio test for power-law distribution and exponential distribution\n",
    "for TOKEN in TOKENS:\n",
    "    velocity = pd.read_csv('{}_microVelocities_last.csv'.format(TOKEN))\n",
    "    velocity = velocity.set_index('timestamp')\n",
    "    velocity = velocity.drop(['total'],axis=1)\n",
    "    velocity = pd.DataFrame(velocity.T)\n",
    "    DATES_ = velocity.columns.values.tolist()\n",
    "    velocity = velocity.reset_index()\n",
    "    R_exp = {}\n",
    "    p_exp = {}\n",
    "    for DATE in DATES_:\n",
    "        v = velocity[['index',DATE]]\n",
    "        v = v.sort_values(by=[DATE],ascending=False)\n",
    "        v = v.loc[v[DATE] > 0]\n",
    "        v[DATE] = v[DATE] / v[DATE].sum()\n",
    "        d1 = v[DATE].to_numpy()\n",
    "        fit = powerlaw.Fit(d1)\n",
    "        R, p = fit.distribution_compare('power_law', 'exponential')\n",
    "        R_exp[DATE] = R\n",
    "        p_exp[DATE] = p\n",
    "\n",
    "    df1 = pd.DataFrame.from_dict(R_exp, orient='index',columns=['R-value']).reset_index()\n",
    "    df1 = df1.rename(columns={'index':'timestamp'})\n",
    "    df2 = pd.DataFrame.from_dict(p_exp, orient='index',columns=['p-value']).reset_index()\n",
    "    df2 = df2.rename(columns={'index':'timestamp'})\n",
    "    df1 = df1.merge(df2, on=['timestamp'], how='left')\n",
    "    df1.to_csv('{}_loglikelihood_ratio.csv'.format(TOKEN), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('{}.csv'.format(TOKEN))\n",
    "a.alpha.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates CCDF for all tokens on the given DATES\n",
    "DATES = ['2019-01-01','2020-01-01','2021-01-01','2022-01-01']\n",
    "dct1 = {}\n",
    "for TOKEN in TOKENS:\n",
    "    dct2 = {}\n",
    "    velocity = pd.read_csv('{}_microVelocities_last.csv'.format(TOKEN))\n",
    "    velocity = velocity.set_index('timestamp')\n",
    "    velocity = velocity.drop(['total'],axis=1)\n",
    "    velocity = pd.DataFrame(velocity.T)\n",
    "    DATES_ = velocity.columns.values.tolist()\n",
    "    velocity = velocity.reset_index()\n",
    "    print('done')\n",
    "    for DATE in DATES:\n",
    "        if DATE in DATES_:\n",
    "            v = velocity[['index',DATE]]\n",
    "            v = v.sort_values(by=[DATE],ascending=False)\n",
    "            v = v.loc[v[DATE] > 0]\n",
    "            v[DATE] = v[DATE] / v[DATE].sum()\n",
    "            d1 = v[DATE].to_numpy()\n",
    "            dct2[DATE] = d1\n",
    "    dct1[TOKEN] = dct2\n",
    "    \n",
    "f = open(\"TOKENS_ccdf.pkl\",\"wb\")\n",
    "pickle.dump(dct1,f)\n",
    "f.close()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = pd.read_pickle('TOKENS_ccdf.pkl')\n",
    "date = ['2019-01-01','2020-01-01','2021-01-01','2022-01-01']\n",
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(12,3.3))\n",
    "\n",
    "# powerlaw.plot_ccdf(data=dct['BUSD'][date[0]],color=colors[0],ax=axes[0])\n",
    "powerlaw.plot_ccdf(data=dct['GUSD'][date[0]],color=colors[1],ax=axes[0])\n",
    "powerlaw.plot_ccdf(data=dct['EURS'][date[0]],color=colors[2],ax=axes[0])\n",
    "powerlaw.plot_ccdf(data=dct['XCHF'][date[0]],color=colors[3],ax=axes[0])\n",
    "# powerlaw.plot_ccdf(data=dct['XAUt'][date[0]],color=colors[4],ax=axes[0])\n",
    "powerlaw.plot_ccdf(data=dct['sUSD'][date[0]],color=colors[5],ax=axes[0])\n",
    "# powerlaw.plot_ccdf(data=dct['FRAX'][date[0]],color=colors[6],ax=axes[0])\n",
    "# powerlaw.plot_ccdf(data=dct['FEI'][date[0]],color=colors[7],ax=axes[0])\n",
    "powerlaw.plot_ccdf(data=ran,color='darkorange',ax=axes[0])\n",
    "\n",
    "axes[0].set_title(date[0], weight='bold')\n",
    "axes[0].tick_params(axis='both', which='minor', bottom=False, left=False)\n",
    "axes[0].set_xlabel(r'$V_i \\,\\,/\\, V$', size=16)\n",
    "axes[0].set_ylabel('CCDF',weight='bold')\n",
    "\n",
    "powerlaw.plot_ccdf(data=dct['BUSD'][date[1]],color=colors[0],ax=axes[1])\n",
    "powerlaw.plot_ccdf(data=dct['GUSD'][date[1]],color=colors[1],ax=axes[1])\n",
    "powerlaw.plot_ccdf(data=dct['EURS'][date[1]],color=colors[2],ax=axes[1])\n",
    "powerlaw.plot_ccdf(data=dct['XCHF'][date[1]],color=colors[3],ax=axes[1])\n",
    "#powerlaw.plot_ccdf(data=dct['XAUt'][date[1]],color=colors[4],ax=axes[1])\n",
    "powerlaw.plot_ccdf(data=dct['sUSD'][date[1]],color=colors[5],ax=axes[1])\n",
    "#powerlaw.plot_ccdf(data=dct['FRAX'][date[1]],color=colors[6],ax=axes[1])\n",
    "#powerlaw.plot_ccdf(data=dct['FEI'][date[1]],color=colors[7],ax=axes[1])\n",
    "\n",
    "axes[1].set_title(date[1], weight='bold')\n",
    "axes[1].tick_params(axis='both', which='minor', bottom=False, left=False)\n",
    "axes[1].set_xlabel(r'$V_i \\,\\,/\\, V$', size=16)\n",
    "axes[1].set_ylabel('CCDF',weight='bold')\n",
    "\n",
    "powerlaw.plot_ccdf(data=dct['BUSD'][date[2]],color=colors[0],ax=axes[2])\n",
    "powerlaw.plot_ccdf(data=dct['GUSD'][date[2]],color=colors[1],ax=axes[2])\n",
    "powerlaw.plot_ccdf(data=dct['EURS'][date[2]],color=colors[2],ax=axes[2])\n",
    "powerlaw.plot_ccdf(data=dct['XCHF'][date[2]],color=colors[3],ax=axes[2])\n",
    "powerlaw.plot_ccdf(data=dct['XAUt'][date[2]],color=colors[4],ax=axes[2])\n",
    "powerlaw.plot_ccdf(data=dct['sUSD'][date[2]],color=colors[5],ax=axes[2])\n",
    "powerlaw.plot_ccdf(data=dct['FRAX'][date[2]],color=colors[6],ax=axes[2])\n",
    "#powerlaw.plot_ccdf(data=dct['FEI'][date[2]],color=colors[7],ax=axes[2])\n",
    "\n",
    "axes[2].set_title(date[2], weight='bold')\n",
    "axes[2].tick_params(axis='both', which='minor', bottom=False, left=False)\n",
    "axes[2].set_xlabel(r'$V_i \\,\\,/\\, V$', size=16)\n",
    "axes[2].set_ylabel('CCDF',weight='bold')\n",
    "\n",
    "powerlaw.plot_ccdf(data=dct['BUSD'][date[3]],color=colors[0],ax=axes[3])\n",
    "powerlaw.plot_ccdf(data=dct['GUSD'][date[3]],color=colors[1],ax=axes[3])\n",
    "powerlaw.plot_ccdf(data=dct['EURS'][date[3]],color=colors[2],ax=axes[3])\n",
    "powerlaw.plot_ccdf(data=dct['XCHF'][date[3]],color=colors[3],ax=axes[3])\n",
    "powerlaw.plot_ccdf(data=dct['XAUt'][date[3]],color=colors[4],ax=axes[3])\n",
    "powerlaw.plot_ccdf(data=dct['sUSD'][date[3]],color=colors[5],ax=axes[3])\n",
    "powerlaw.plot_ccdf(data=dct['FRAX'][date[3]],color=colors[6],ax=axes[3])\n",
    "powerlaw.plot_ccdf(data=dct['FEI'][date[3]],color=colors[7],ax=axes[3])\n",
    "  \n",
    "axes[3].set_title(date[3], weight='bold')\n",
    "axes[3].tick_params(axis='both', which='minor', bottom=False, left=False)\n",
    "axes[3].legend(['BUSD','GUSD','EURS','XCHF','XAUt','sUSD','FRAX','FEI'],loc='lower left')\n",
    "axes[3].set_xlabel(r'$V_i \\,\\,/\\, V$', size=16)\n",
    "axes[3].set_ylabel('CCDF',weight='bold')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('image_ccdf.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates Spearman rank correlation between microVelocity and balance of an agent\n",
    "for TOKEN in TOKENS:\n",
    "    balances = pd.read_csv('{}_balances_daily.csv'.format(TOKEN))\n",
    "    balances = balances.set_index('timestamp')\n",
    "    velocity = pd.read_csv('{}_microVelocities_last.csv'.format(TOKEN))\n",
    "    velocity = velocity.set_index('timestamp')\n",
    "    velocity = velocity.drop(['total'],axis=1)\n",
    "\n",
    "    balances = pd.DataFrame(balances.T)\n",
    "    velocity = pd.DataFrame(velocity.T)\n",
    "    dates = balances.columns.values.tolist()\n",
    "    balances = balances.reset_index()\n",
    "    velocity = velocity.reset_index()\n",
    "\n",
    "    cor = {}\n",
    "    for date in dates:\n",
    "        b = balances[['index',date]]\n",
    "        b = b.sort_values(by=[date],ascending=False)\n",
    "        b = b.loc[b[date] > 0]\n",
    "        v = velocity[['index',date]]\n",
    "        v = v.sort_values(by=[date],ascending=False)\n",
    "        v = v.loc[v[date] > 0]\n",
    "        m = b.merge(v, on=['index'], how='left').dropna()\n",
    "        df = m[['{}_x'.format(date),'{}_y'.format(date)]]\n",
    "        cor[date] = spearmanr(df).correlation\n",
    "    df = pd.DataFrame.from_dict(cor, orient='index',columns=[TOKEN]).reset_index()\n",
    "    df = df.rename(columns={'index':'timestamp'})\n",
    "    df.to_csv('{}_spearman.csv'.format(TOKEN), index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENS = ['FRAX','BUSD', 'GUSD', 'EURS', 'XCHF', 'XAUt','FEI']\n",
    "df1 = pd.read_csv('sUSD_spearman.csv')\n",
    "for TOKEN in TOKENS:\n",
    "    df2 = pd.read_csv('{}_spearman.csv'.format(TOKEN))\n",
    "    df1 = df1.merge(df2,on=['timestamp'], how='left')\n",
    "df1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spear = pd.read_csv('spearman.csv', parse_dates=['timestamp'])\n",
    "ax = spear.plot(x='timestamp', y=['sUSD','EURS','GUSD','XCHF','BUSD','XAUt','FRAX','FEI'],\n",
    "        kind='line',\n",
    "        figsize=(13.4,3),\n",
    "        color=[colors[5],colors[2],colors[1],colors[3],colors[0],colors[4],colors[6],colors[7]],\n",
    "        rot=0,\n",
    "        label=['sUSD','EURS','GUSD','XCHF','BUSD','XAUt','FRAX','FEI'],\n",
    "        lw=1.5,\n",
    "        style=['-','-','-','-','-','-','-','-'],\n",
    "        x_compat=True)     \n",
    "\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel(r'$\\rho(M_i,V_i)$', size=16)\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator(bymonth=range(1,13,6)))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d')) \n",
    "ax.yaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "ax.legend(['sUSD', 'EURS', 'GUSD', 'XCHF', 'BUSD', 'XAUt', 'FRAX', 'FEI'], loc='center right',bbox_to_anchor=(1.13, 0.5))\n",
    "\n",
    "for tick in ax.xaxis.get_majorticklabels():\n",
    "    tick.set_horizontalalignment(\"center\") \n",
    "plt.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='major',      # both major and minor ticks are affected\n",
    "    bottom=True,      # ticks along the bottom edge are off\n",
    "    top=False,\n",
    "    left=True)         # ticks along the top edge are off\n",
    "plt.savefig('image_spearman_over_time.png')\n",
    "plt.show()           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman rank correlation scatter plot data for each token\n",
    "DATES = ['2019-01-01','2020-01-01','2021-01-01','2022-01-01']\n",
    "\n",
    "for TOKEN in TOKENS:\n",
    "    dct = {}\n",
    "    for DATE in DATES:\n",
    "        balances = pd.read_csv('{}_balances_daily.csv'.format(TOKEN))\n",
    "        balances = balances.set_index('timestamp')\n",
    "        velocity = pd.read_csv('{}_microVelocities_last.csv'.format(TOKEN))\n",
    "        velocity = velocity.set_index('timestamp')\n",
    "        velocity = velocity.drop(['total'],axis=1)\n",
    "\n",
    "        balances = pd.DataFrame(balances.T)\n",
    "        velocity = pd.DataFrame(velocity.T)\n",
    "        DATES_ = balances.columns.values.tolist()\n",
    "        balances = balances.reset_index()\n",
    "        velocity = velocity.reset_index()\n",
    "        if DATE in DATES_:\n",
    "            b = balances[['index',DATE]]\n",
    "            b = b.sort_values(by=[DATE],ascending=False)\n",
    "            b = b.loc[b[DATE] > 0]\n",
    "            b[DATE] = b[DATE] / b[DATE].sum()\n",
    "            v = velocity[['index',DATE]]\n",
    "            v = v.sort_values(by=[DATE],ascending=False)\n",
    "            v = v.loc[v[DATE] > 0]\n",
    "            v[DATE] = v[DATE] / v[DATE].sum()\n",
    "            m = b.merge(v, on=['index'], how='left').dropna()\n",
    "            m = m.rename(columns={'{}_x'.format(DATE):'M_{}'.format(TOKEN),'{}_y'.format(DATE):'V_{}'.format(TOKEN)})\n",
    "            M = m['M_{}'.format(TOKEN)].to_list()\n",
    "            V = m['V_{}'.format(TOKEN)].to_list()\n",
    "            dct[DATE] = [M,V]\n",
    "        else:\n",
    "            dct[DATE] = [[],[]]\n",
    "            \n",
    "    f = open(\"{}_spearman_snapshots.pkl\".format(TOKEN),\"wb\")\n",
    "    pickle.dump(dct,f)\n",
    "    f.close() \n",
    "    print(\"{}_spearman_snapshots.pkl: success\".format(TOKEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['mathtext.fontset'] = 'stix'\n",
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(13.4,3))\n",
    "\n",
    "susd = pd.read_pickle('sUSD_spearman_snapshots.pkl')\n",
    "eurs = pd.read_pickle('EURS_spearman_snapshots.pkl')\n",
    "gusd = pd.read_pickle('GUSD_spearman_snapshots.pkl')\n",
    "xchf = pd.read_pickle('XCHF_spearman_snapshots.pkl')\n",
    "busd = pd.read_pickle('BUSD_spearman_snapshots.pkl')\n",
    "xaut = pd.read_pickle('XAUt_spearman_snapshots.pkl')\n",
    "frax = pd.read_pickle('FRAX_spearman_snapshots.pkl')\n",
    "fei = pd.read_pickle('FEI_spearman_snapshots.pkl')\n",
    "\n",
    "axes[0].scatter(susd['2019-01-01'][0], susd['2019-01-01'][1], s=40, edgecolor=colors[5], facecolor='None', marker=\"o\", label='sUSD')\n",
    "axes[0].scatter(eurs['2019-01-01'][0], eurs['2019-01-01'][1], s=40, edgecolor=colors[2], facecolor='None', marker=\"s\", label='EURS')\n",
    "axes[0].scatter(gusd['2019-01-01'][0], gusd['2019-01-01'][1], s=40, edgecolor=colors[1], facecolor='None', marker='^', label='GUSD')\n",
    "axes[0].scatter(xchf['2019-01-01'][0], xchf['2019-01-01'][1], s=40, edgecolor=colors[3], facecolor='None', marker=\"1\", label='XCHF')\n",
    "axes[0].scatter(busd['2019-01-01'][0], busd['2019-01-01'][1], s=40, edgecolor=colors[0], facecolor='None', marker=\"+\", label='BUSD')\n",
    "axes[0].scatter(xaut['2019-01-01'][0], xaut['2019-01-01'][1], s=40, edgecolor=colors[4], facecolor='None', marker=\"x\", label='XAUt')\n",
    "axes[0].scatter(frax['2019-01-01'][0], frax['2019-01-01'][1], s=40, edgecolor=colors[6], facecolor='None', marker=\"D\", label='FRAX')\n",
    "axes[0].scatter(fei['2019-01-01'][0], fei['2019-01-01'][1], s=40, edgecolor=colors[7], facecolor='None', marker=\"*\", label='FEI')\n",
    "axes[0].axline([0, 0], [1, 1], c='darkorange', lw=2.5, ls='--')\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].set_ylim(1 * 10**(-21),100)\n",
    "axes[0].set_xlim(1 * 10**(-21),100)\n",
    "axes[0].set_title('2019-01-01', weight='bold')\n",
    "axes[0].set_yticklabels([])\n",
    "axes[0].set_xticklabels([])\n",
    "axes[0].set_xlabel(r'$M_i\\,\\,/\\,M$', size=16)\n",
    "axes[0].set_ylabel(r'$V_i\\,\\,/\\,V$', size=16)\n",
    "axes[0].tick_params(left=False)\n",
    "axes[0].tick_params(axis='both', which='major', bottom=False, left=False)\n",
    "\n",
    "axes[1].scatter(susd['2020-01-01'][0], susd['2020-01-01'][1], s=40, edgecolor=colors[5], facecolor='None', marker=\"o\", label='sUSD')\n",
    "axes[1].scatter(eurs['2020-01-01'][0], eurs['2020-01-01'][1], s=40, edgecolor=colors[2], facecolor='None', marker=\"s\", label='EURS')\n",
    "axes[1].scatter(gusd['2020-01-01'][0], gusd['2020-01-01'][1], s=40, edgecolor=colors[1], facecolor='None', marker='^', label='GUSD')\n",
    "axes[1].scatter(xchf['2020-01-01'][0], xchf['2020-01-01'][1], s=40, edgecolor=colors[3], facecolor='None', marker=\"1\", label='XCHF')\n",
    "axes[1].scatter(busd['2020-01-01'][0], busd['2020-01-01'][1], s=40, edgecolor=colors[0], facecolor='None', marker=\"+\", label='BUSD')\n",
    "axes[1].scatter(xaut['2020-01-01'][0], xaut['2020-01-01'][1], s=40, edgecolor=colors[4], facecolor='None', marker=\"x\", label='XAUt')\n",
    "axes[1].scatter(frax['2020-01-01'][0], frax['2020-01-01'][1], s=40, edgecolor=colors[6], facecolor='None', marker=\"D\", label='FRAX')\n",
    "axes[1].scatter(fei['2020-01-01'][0], fei['2020-01-01'][1], s=40, edgecolor=colors[7], facecolor='None', marker=\"*\", label='FEI')\n",
    "axes[1].axline([0, 0], [1, 1], c='darkorange', lw=2.5, ls='--')\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].set_ylim(1 * 10**(-17),100)\n",
    "axes[1].set_xlim(1 * 10**(-17),100)\n",
    "axes[1].set_title('2020-01-01', weight='bold')\n",
    "axes[1].set_yticklabels([])\n",
    "axes[1].set_xticklabels([])\n",
    "axes[1].set_xlabel(r'$M_i\\,\\,/\\,M$', size=16)\n",
    "axes[1].set_ylabel(r'$V_i\\,\\,/\\,V$', size=16)\n",
    "axes[1].tick_params(left=False)\n",
    "axes[1].tick_params(axis='both', which='major', bottom=False, left=False)\n",
    "\n",
    "axes[2].scatter(susd['2021-01-01'][0], susd['2021-01-01'][1], s=40, edgecolor=colors[5], facecolor='None', marker=\"o\", label='sUSD')\n",
    "axes[2].scatter(eurs['2021-01-01'][0], eurs['2021-01-01'][1], s=40, edgecolor=colors[2], facecolor='None', marker=\"s\", label='EURS')\n",
    "axes[2].scatter(gusd['2021-01-01'][0], gusd['2021-01-01'][1], s=40, edgecolor=colors[1], facecolor='None', marker='^', label='GUSD')\n",
    "axes[2].scatter(xchf['2021-01-01'][0], xchf['2021-01-01'][1], s=40, edgecolor=colors[3], facecolor='None', marker=\"1\", label='XCHF')\n",
    "axes[2].scatter(busd['2021-01-01'][0], busd['2021-01-01'][1], s=40, edgecolor=colors[0], facecolor='None', marker=\"+\", label='BUSD')\n",
    "axes[2].scatter(xaut['2021-01-01'][0], xaut['2021-01-01'][1], s=40, edgecolor=colors[4], facecolor='None', marker=\"x\", label='XAUt')\n",
    "axes[2].scatter(frax['2021-01-01'][0], frax['2021-01-01'][1], s=40, edgecolor=colors[6], facecolor='None', marker=\"D\", label='FRAX')\n",
    "axes[2].scatter(fei['2021-01-01'][0], fei['2021-01-01'][1], s=40, edgecolor=colors[7], facecolor='None', marker=\"*\", label='FEI')\n",
    "axes[2].axline([0, 0], [1, 1], c='darkorange', lw=2.5, ls='--')\n",
    "axes[2].set_yscale('log')\n",
    "axes[2].set_xscale('log')\n",
    "axes[2].set_ylim(1 * 10**(-23),100)\n",
    "axes[2].set_xlim(1 * 10**(-23),100)\n",
    "axes[2].set_title('2021-01-01', weight='bold')\n",
    "axes[2].set_yticklabels([])\n",
    "axes[2].set_xticklabels([])\n",
    "axes[2].set_xlabel(r'$M_i\\,\\,/\\,M$', size=16)\n",
    "axes[2].set_ylabel(r'$V_i\\,\\,/\\,V$', size=16)\n",
    "axes[2].tick_params(left=False)\n",
    "axes[2].tick_params(axis='both', which='major', bottom=False, left=False)\n",
    "\n",
    "axes[3].scatter(susd['2022-01-01'][0], susd['2022-01-01'][1], s=40, edgecolor=colors[5], facecolor='None', marker=\"o\", label='sUSD')\n",
    "axes[3].scatter(eurs['2022-01-01'][0], eurs['2022-01-01'][1], s=40, edgecolor=colors[2], facecolor='None', marker=\"s\", label='EURS')\n",
    "axes[3].scatter(gusd['2022-01-01'][0], gusd['2022-01-01'][1], s=40, edgecolor=colors[1], facecolor='None', marker='^', label='GUSD')\n",
    "axes[3].scatter(xchf['2022-01-01'][0], xchf['2022-01-01'][1], s=40, facecolor=colors[3], marker=\"1\", label='XCHF')\n",
    "axes[3].scatter(busd['2022-01-01'][0], busd['2022-01-01'][1], s=40, facecolor=colors[0], marker=\"+\", label='BUSD')\n",
    "axes[3].scatter(xaut['2022-01-01'][0], xaut['2022-01-01'][1], s=40, facecolor=colors[4], marker=\"x\", label='XAUt')\n",
    "axes[3].scatter(frax['2022-01-01'][0], frax['2022-01-01'][1], s=40, edgecolor=colors[6], facecolor='None', marker=\"D\", label='FRAX')\n",
    "axes[3].scatter(fei['2022-01-01'][0], fei['2022-01-01'][1], s=40, edgecolor=colors[7], facecolor='None', marker=\"*\", label='FEI')\n",
    "axes[3].axline([0, 0], [1, 1], c='darkorange', lw=2.5, ls='--')\n",
    "axes[3].set_yscale('log')\n",
    "axes[3].set_xscale('log')\n",
    "axes[3].set_ylim(1 * 10**(-23),100)\n",
    "axes[3].set_xlim(1 * 10**(-23),100)\n",
    "axes[3].set_title('2022-01-01', weight='bold')\n",
    "axes[3].set_yticklabels([])\n",
    "axes[3].set_xticklabels([])\n",
    "axes[3].set_xlabel(r'$M_i\\,\\,/\\,M$', size=16)\n",
    "axes[3].set_ylabel(r'$V_i\\,\\,/\\,V$', size=16)\n",
    "axes[3].tick_params(left=False)\n",
    "axes[3].tick_params(axis='both', which='major', bottom=False, left=False)\n",
    "axes[3].legend([r'$V_i\\,\\,/\\,V = M_i\\,\\,/\\,M$', 'sUSD', 'EURS', 'GUSD', 'XCHF', 'BUSD', 'XAUt', 'FRAX', 'FEI'], loc='center right',bbox_to_anchor=(1.8, 0.5))\n",
    "fig.tight_layout()\n",
    "plt.savefig('image_spearman_scatter.png')\n",
    "plt.subplots_adjust(wspace=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentages for every log-likelihood ratio test\n",
    "df = pd.read_csv('FEI_dist_comp_exp.csv')\n",
    "df = df[:-1]\n",
    "R = df.loc[df['R-value'] > 0]\n",
    "p = df.loc[df['p-value'] < 0.05]\n",
    "print(len(R)/(len(df)))\n",
    "print(len(p)/(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates number of addresses with nonzero balance\n",
    "\n",
    "def getBalance(block, address):\n",
    "    d = balances[address]\n",
    "    valid_keys = [key for key in d if key <= block]\n",
    "    if valid_keys == []:\n",
    "        return 0\n",
    "    else:\n",
    "        balance = d[block] if block in d else d[min(valid_keys, key=lambda k: abs(k-block))] \n",
    "        return int(balance)\n",
    "\n",
    "for i in range(len(TOKENS)):\n",
    "    TOKEN = TOKENS[i]\n",
    "    FIRST_BLOCK = FIRST_BLOCKS[i]\n",
    "    ts = pd.read_csv('block_timestamps_complete.csv', parse_dates=['timestamp'])\n",
    "    ts = ts.loc[(ts.block_number >= FIRST_BLOCK) & (ts.block_number <= LAST_BLOCK)]\n",
    "    last = pd.DataFrame(ts[['timestamp','block_number']].groupby(pd.Grouper(key='timestamp', axis=0, freq='W')).last()).reset_index()\n",
    "    blocks = last['block_number'].to_list()\n",
    "    timestamps = last['timestamp'].to_list()\n",
    "    balances = pd.read_pickle('{}_balances.pkl'.format(TOKEN))\n",
    "    addresses = list(balances.keys())\n",
    "    numberOfAddresses = []                        \n",
    "    for block in blocks:\n",
    "        num = 0\n",
    "        for address in addresses:\n",
    "            if getBalance(block,address) != 0:\n",
    "                num+=1\n",
    "        numberOfAddresses.append(num)\n",
    "    if TOKEN == 'sUSD':    \n",
    "        df0 = pd.DataFrame({'timestamp':timestamps, TOKEN:numberOfAddresses}) \n",
    "    else:\n",
    "        df1 = pd.DataFrame({'timestamp':timestamps, TOKEN:numberOfAddresses}) \n",
    "        df0 = df0.merge(df1, on=['timestamp'], how='left')\n",
    "    df0.to_csv('nonzero_addresses.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates number of active addresses (that sent transaction in a given week)\n",
    "for i in range(len(TOKENS)):\n",
    "    TOKEN = TOKENS[i]\n",
    "    FIRST_BLOCK = FIRST_BLOCKS[i]\n",
    "    ts = pd.read_csv('block_timestamps_complete.csv', parse_dates=['timestamp'])\n",
    "    ts = ts.loc[(ts.block_number >= FIRST_BLOCK) & (ts.block_number <= LAST_BLOCK)]\n",
    "    last = pd.DataFrame(ts[['timestamp','block_number']].groupby(pd.Grouper(key='timestamp', axis=0, freq='D')).first()).reset_index()\n",
    "    blocks = last['block_number'].to_list()\n",
    "    timestamps = last['timestamp'].to_list()\n",
    "    transfers = pd.read_csv('{}_token_transfers.csv'.format(TOKEN), parse_dates=['timestamp'])\n",
    "    transfers['timestamp'] = pd.to_datetime((transfers['timestamp']).dt.date)\n",
    "    numberOfUniques = []                        \n",
    "    for t in timestamps:\n",
    "        _transfers = transfers.loc[transfers.timestamp == t]\n",
    "        from_address = _transfers.from_address.to_list()\n",
    "        to_address = _transfers.to_address.to_list()\n",
    "        numberOfUniques.append(len(set(from_address + to_address)))\n",
    "    if TOKEN == 'sUSD':    \n",
    "        df0 = pd.DataFrame({'timestamp':timestamps, '{}_transfer'.format(TOKEN):numberOfUniques}) \n",
    "    else:\n",
    "        df1 = pd.DataFrame({'timestamp':timestamps, '{}_transfer'.format(TOKEN):numberOfUniques}) \n",
    "        df0 = df0.merge(df1, on=['timestamp'], how='left')\n",
    "    df0 = pd.DataFrame(df0.groupby(pd.Grouper(key='timestamp', axis=0, freq='W')).sum()).reset_index()\n",
    "    df0.to_csv('active_addresses.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques = pd.read_csv('unique_addresses.csv', parse_dates=['timestamp'])\n",
    "nonzero = pd.read_csv('nonzero_addresses.csv', parse_dates=['timestamp'])\n",
    "active = pd.read_csv('active_addresses.csv', parse_dates=['timestamp'])\n",
    "merge = uniques.merge(active, on=['timestamp'])\n",
    "merge = merge.merge(transfer, on=['timestamp'], how='left').fillna(method='ffill')\n",
    "\n",
    "fig, axes = plt.subplots(nrows=4, ncols=2)\n",
    "\n",
    "b = merge.plot(x='timestamp', y=['BUSD_x','BUSD_y','BUSD_transfer'],\n",
    "        ax=axes[0,0],       \n",
    "        kind='line',\n",
    "        figsize=(5,5),\n",
    "        color=[colors[4],colors[2],colors[1]],\n",
    "        rot=0,\n",
    "        lw=1,\n",
    "        style=['--','-'],\n",
    "        x_compat=True, \n",
    "        sharex=True,\n",
    "        legend=False)\n",
    "\n",
    "b.set_title('BUSD') \n",
    "b.set_xlabel('')\n",
    "b.xaxis.set_major_locator(mdates.MonthLocator(bymonth=range(1,13,12)))\n",
    "b.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "b.set_yscale('log')\n",
    "b.yaxis.set_major_formatter(ScalarFormatter())\n",
    "b.tick_params(axis='y', which='minor', left=False)\n",
    "b.tick_params(axis='x', which='both', bottom=False)\n",
    "for tick in b.xaxis.get_majorticklabels():\n",
    "    tick.set_horizontalalignment(\"center\")\n",
    "    \n",
    "g = merge.plot(x='timestamp', y=['GUSD_x','GUSD_y','GUSD_transfer'],\n",
    "        ax=axes[0,1],      \n",
    "        kind='line',\n",
    "        figsize=(5,5),\n",
    "        color=[colors[4],colors[2],colors[1]],\n",
    "        rot=0,\n",
    "        lw=1,\n",
    "        style=['--','-'],\n",
    "        x_compat=True,\n",
    "        sharex=True,\n",
    "        legend=False)\n",
    "\n",
    "g.set_title('GUSD') \n",
    "g.set_xlabel('')\n",
    "g.xaxis.set_major_locator(mdates.MonthLocator(bymonth=range(1,13,12)))\n",
    "g.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "g.set_yscale('log')\n",
    "g.yaxis.set_major_formatter(ScalarFormatter())\n",
    "g.tick_params(axis='y', which='minor', left=False)\n",
    "g.tick_params(axis='x', which='both', bottom=False)\n",
    "for tick in g.xaxis.get_majorticklabels():\n",
    "    tick.set_horizontalalignment(\"center\")\n",
    "\n",
    "e = merge.plot(x='timestamp', y=['EURS_x','EURS_y','EURS_transfer'],\n",
    "        ax=axes[1,0],       \n",
    "        kind='line',\n",
    "        figsize=(5,5),\n",
    "        color=[colors[4],colors[2],colors[1]],\n",
    "        rot=0,\n",
    "        lw=1,\n",
    "        style=['--','-'],\n",
    "        x_compat=True,\n",
    "        sharex=True,\n",
    "        legend=False)\n",
    "\n",
    "e.set_title('EURS') \n",
    "e.set_xlabel('')\n",
    "e.xaxis.set_major_locator(mdates.MonthLocator(bymonth=range(1,13,12)))\n",
    "e.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "e.set_yscale('log')\n",
    "e.yaxis.set_major_formatter(ScalarFormatter())\n",
    "e.tick_params(axis='y', which='minor', left=False)\n",
    "e.tick_params(axis='x', which='both', bottom=False)\n",
    "for tick in e.xaxis.get_majorticklabels():\n",
    "    tick.set_horizontalalignment(\"center\")\n",
    "\n",
    "xc = merge.plot(x='timestamp', y=['XCHF_x','XCHF_y','XCHF_transfer'],\n",
    "    ax=axes[1,1],      \n",
    "    kind='line',\n",
    "    figsize=(5,5),\n",
    "    color=[colors[4],colors[2],colors[1]],\n",
    "    rot=0,\n",
    "    lw=1,\n",
    "    style=['--','-'],\n",
    "    x_compat=True,\n",
    "    sharex=True,\n",
    "    legend=False)\n",
    "\n",
    "xc.set_title('XCHF') \n",
    "xc.set_xlabel('')\n",
    "xc.xaxis.set_major_locator(mdates.MonthLocator(bymonth=range(1,13,12)))\n",
    "xc.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "xc.set_yscale('log')\n",
    "xc.yaxis.set_major_formatter(ScalarFormatter())\n",
    "xc.tick_params(axis='y', which='minor', left=False)\n",
    "xc.tick_params(axis='x', which='both', bottom=False)\n",
    "for tick in xc.xaxis.get_majorticklabels():\n",
    "    tick.set_horizontalalignment(\"center\")\n",
    "    \n",
    "xa = merge.plot(x='timestamp', y=['XAUt_x','XAUt_y','XAUt_transfer'],\n",
    "        ax=axes[2,0],       \n",
    "        kind='line',\n",
    "        figsize=(5,5),\n",
    "        color=[colors[4],colors[2],colors[1]],\n",
    "        rot=0,\n",
    "        lw=1,\n",
    "        style=['--','-'],\n",
    "        x_compat=True,\n",
    "        sharex=True,\n",
    "        legend=False)\n",
    "\n",
    "xa.set_title('XAUt') \n",
    "xa.set_xlabel('')\n",
    "xa.xaxis.set_major_locator(mdates.MonthLocator(bymonth=range(1,13,12)))\n",
    "xa.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "xa.set_yscale('log')\n",
    "xa.yaxis.set_major_formatter(ScalarFormatter())\n",
    "xa.tick_params(axis='y', which='minor', left=False)\n",
    "xa.tick_params(axis='x', which='both', bottom=False)\n",
    "for tick in xa.xaxis.get_majorticklabels():\n",
    "    tick.set_horizontalalignment(\"center\") \n",
    "    \n",
    "s = merge.plot(x='timestamp', y=['sUSD_x','sUSD_y','sUSD_transfer'],\n",
    "        ax=axes[2,1],\n",
    "        kind='line',\n",
    "        figsize=(4,5),\n",
    "        color=[colors[5],colors[2],colors[1]],\n",
    "        rot=0,\n",
    "        lw=1,\n",
    "        style=['--','-'],\n",
    "        x_compat=True,\n",
    "        sharex=True,\n",
    "        legend=False)\n",
    "\n",
    "s.set_title('sUSD') \n",
    "s.set_xlabel('')\n",
    "s.xaxis.set_major_locator(mdates.MonthLocator(bymonth=range(1,13,12)))\n",
    "s.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "s.set_yscale('log')\n",
    "s.yaxis.set_major_formatter(ScalarFormatter())\n",
    "s.tick_params(axis='y', which='minor', left=False)\n",
    "s.tick_params(axis='x', which='both', bottom=False)\n",
    "for tick in s.xaxis.get_majorticklabels():\n",
    "    tick.set_horizontalalignment(\"center\")\n",
    "\n",
    "fr = merge.plot(x='timestamp', y=['FRAX_x','FRAX_y','FRAX_transfer'],\n",
    "        ax=axes[3,0],\n",
    "        kind='line',\n",
    "        figsize=(5,5),\n",
    "        color=[colors[4],colors[2],colors[1]],\n",
    "        rot=0,\n",
    "        lw=1,\n",
    "        style=['--','-'],\n",
    "        x_compat=True,\n",
    "        sharex=True,\n",
    "        legend=False)\n",
    "\n",
    "fr.set_title('FRAX') \n",
    "fr.set_xlabel('')\n",
    "fr.xaxis.set_major_locator(mdates.MonthLocator(bymonth=range(1,13,12)))\n",
    "fr.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "fr.set_yscale('log')\n",
    "fr.yaxis.set_major_formatter(ScalarFormatter())\n",
    "fr.tick_params(axis='y', which='minor', left=False)\n",
    "fr.tick_params(axis='x', which='minor', bottom=False)\n",
    "for tick in fr.xaxis.get_majorticklabels():\n",
    "    tick.set_horizontalalignment(\"center\")\n",
    "    \n",
    "fe = merge.plot(x='timestamp', y=['FEI_x','FEI_y','FEI_transfer'],\n",
    "        ax=axes[3,1],\n",
    "        kind='line',\n",
    "        figsize=(10,10),\n",
    "        color=[colors[4],colors[2],colors[1]],\n",
    "        rot=0,\n",
    "        lw=1,\n",
    "        label=['Unique addresses','Addresses with nonzero balances','Weekly active addresses'],\n",
    "        style=['--','-'],\n",
    "        x_compat=True,\n",
    "        sharex=True)\n",
    "\n",
    "fe.set_title('FEI') \n",
    "fe.set_xlabel('')\n",
    "fe.xaxis.set_major_locator(mdates.MonthLocator(bymonth=range(1,13,12)))\n",
    "fe.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "fe.set_yscale('log')\n",
    "fe.yaxis.set_major_formatter(ScalarFormatter())\n",
    "fe.tick_params(axis='y', which='minor', left=False)\n",
    "fe.tick_params(axis='x', which='minor', bottom=False)\n",
    "for tick in fe.xaxis.get_majorticklabels():\n",
    "    tick.set_horizontalalignment(\"center\")\n",
    "   \n",
    "fig.tight_layout()\n",
    "fig.text(-0.02, 0.5, 'Number of Addresses', va='center', rotation='vertical', size=12, weight='bold')\n",
    "fig.text(0.5, 0, 'Date', va='center', size=12, weight='bold')\n",
    "plt.savefig('image_activeness.png', bbox_inches='tight')\n",
    "plt.show()                     "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
